lasdi.latent_space
==================

.. py:module:: lasdi.latent_space


Classes
-------

.. autoapisummary::

   lasdi.latent_space.MultiLayerPerceptron
   lasdi.latent_space.CNN2D
   lasdi.latent_space.LatentSpace
   lasdi.latent_space.Autoencoder
   lasdi.latent_space.Conv2DAutoencoder


Functions
---------

.. autoapisummary::

   lasdi.latent_space.initial_condition_latent


Package Contents
----------------

.. py:class:: MultiLayerPerceptron(layer_sizes, act_type='sigmoid', reshape_index=None, reshape_shape=None, threshold=0.1, value=0.0)

   Bases: :py:obj:`torch.nn.Module`


   Vanilla multi-layer perceptron neural networks module.


   :Parameters: * **layer_sizes** (:obj:`list(int)`) -- List of vector dimensions of layers.
                * **act_type** (:obj:`str`, optional) -- Type of activation functions. By default :obj:`'sigmoid'` is used.
                  See :obj:`act_dict` for available types.
                * **reshape_index** (:obj:`int`, optinal) -- Index of layer to reshape input/output data. Either 0 or -1 is allowed.

                  - 0 : the first (input) layer
                  - -1 : the last (output) layer

                  By default the index is :obj:`None`, and reshaping is not executed.
                * **reshape_shape** (:obj:`list(int)`, optional) -- Target shape from/to which input/output data is reshaped.
                  Reshaping behavior changes by :attr:`reshape_index`.
                  By default the index is :obj:`None`, and reshaping is not executed.
                  For details on reshaping action, see :attr:`reshape_shape`.

   .. note:: :obj:`numpy.prod(reshape_shape) == layer_sizes[reshape_index]`


   .. py:attribute:: n_layers

      Depth of layers including input, hidden, output layers.

      :type: :obj:`int`


   .. py:attribute:: layer_sizes

      Vector dimensions corresponding to each layer.

      :type: :obj:`list(int)`


   .. py:attribute:: fcs
      :value: []


      linear features between layers.

      :type: :obj:`torch.nn.ModuleList`


   .. py:attribute:: reshape_index

      Index of layer to reshape input/output data.

      - 0 : the first (input) layer
      - -1 : the last (output) layer
      - :obj:`None` : no reshaping

      :type: :obj:`int`


   .. py:attribute:: reshape_shape

      Target shape from/to which input/output data is reshaped.
      For a reshape_shape :math:`[R_1, R_2, \ldots, R_n]`,

      - if :attr:`reshape_index` is 0, the input data shape is changed as

      .. math::
          [\ldots, R_1, R_2, \ldots, R_n] \longrightarrow [\ldots, \prod_{i=1}^n R_i]

      - if :attr:`reshape_index` is -1, the output data shape is changed as

      .. math::
          [\ldots, \prod_{i=1}^n R_i] \longrightarrow [\ldots, R_1, R_2, \ldots, R_n]

      - :obj:`None` : no reshaping

      :type: :obj:`list(int)`


   .. py:attribute:: act_type

      Type of activation functions.

      :type: :obj:`str`


   .. py:attribute:: act

      Activation function used throughout the layers.

      :type: :obj:`torch.nn.Module`


   .. py:method:: forward(x)

      Evaluate through the module.

      :Parameters: **x** (:obj:`torch.Tensor`) -- Input data to pass into the module.

      .. note::

         For :attr:`reshape_index` =0,
         the last :math:`n` dimensions of :obj:`x` must match
         :attr:`reshape_shape` :math:`=[R_1, R_2, \ldots, R_n]`.

      :returns: Output tensor evaluated from the module.
      :rtype: :obj:`torch.Tensor`

      .. note::

         For :attr:`reshape_index` =-1,
         the last dimension of the output tensor will be reshaped as
         :attr:`reshape_shape` :math:`=[R_1, R_2, \ldots, R_n]`.



   .. py:method:: init_weight()

      Initialize weights of linear features according to Xavier uniform distribution.



   .. py:method:: print_architecture()

      Print out the architecture of the module.



.. py:class:: CNN2D(layer_sizes, mode, strides, paddings, dilations, groups=1, bias=True, padding_mode='zeros', act_type='ReLU', data_shape=None)

   Bases: :py:obj:`torch.nn.Module`


   Two-dimensional convolutional neural networks.

   :Parameters: * **layer_sizes** (:obj:`numpy.array`) -- 2d array of tensor dimension of each layer.
                  See :attr:`layer_sizes`.
                * **mode** (:obj:`str`) -- Direction of CNN
                  - `forward`: contracting direction
                  - `backward`: expanding direction
                * **strides** (:obj:`list`) -- List of strides corresponding to each layer.
                  Each stride is either integer or tuple.
                * **paddings** (:obj:`list`) -- List of paddings corresponding to each layer.
                  Each padding is either integer or tuple.
                * **dilations** (:obj:`list`) -- List of dilations corresponding to each layer.
                  Each dilation is either integer or tuple.
                * **groups** (:obj:`int`, optional) -- Groups that applies to all layers. By default 1
                * **bias** (:obj:`bool`, optional) -- Bias that applies to all layers. By default :obj:`True`
                * **padding_mode** (:obj:`str`, optional) -- Padding_mode that applies to all layers. By default :obj:`'zeros'`
                * **act_type** (:obj:`str`, optional) -- Activation function applied between all layers. By default :obj:`'ReLU'`.
                  See :obj:`act_dict` for available types.
                * **data_shape** (:obj:`list(int)`, optional) -- Data shape to/from which output/input data is reshaped.
                  See :attr:`data_shape` for details.

   .. note::

      :obj:`len(strides) == layer_sizes.shape[0] - 1`

      :obj:`len(paddings) == layer_sizes.shape[0] - 1`

      :obj:`len(dilations) == layer_sizes.shape[0] - 1`


   .. py:class:: Mode

      Bases: :py:obj:`Enum`


      Enumeration to specify direction of CNN.


      .. py:attribute:: Forward
         :value: 1


         Contracting direction


      .. py:attribute:: Backward

         Expanding direction



   .. py:attribute:: n_layers

      Depth of layers including input, hidden, output layers.

      :type: :obj:`int`


   .. py:attribute:: layer_sizes

      2d integer array of shape :math:`[n\_layers, 3]`,
      indicating tensor dimension of each layer.
      For :math:`k`-th layer, the tensor dimension is

      .. math::
          layer\_sizes[k] = [channels, height, width]

      :type: :obj:`numpy.array`


   .. py:attribute:: channels

      list of channel size that
      determines architecture of each layer.
      For details on how architecture is determined,
      see `torch API documentation <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_.

      :type: :obj:`list(int)`


   .. py:attribute:: strides

      list of strides that
      determine architecture of each layer.
      Each stride can be either integer or tuple.
      For details on how architecture is determined,
      see `torch API documentation <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_.

      :type: :obj:`list`


   .. py:attribute:: paddings

      list of paddings that
      determine architecture of each layer.
      Each padding can be either integer or tuple.
      For details on how architecture is determined,
      see `torch API documentation <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_.

      :type: :obj:`list`


   .. py:attribute:: dilations

      list of dilations that
      determine architecture of each layer.
      Each dilation can be either integer or tuple.
      For details on how architecture is determined,
      see `torch API documentation <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_.

      :type: :obj:`list`


   .. py:attribute:: groups

      groups that determine architecture of all layers.
      For details on how architecture is determined,
      see `torch API documentation <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_.

      :type: :obj:`int`


   .. py:attribute:: bias

      bias that determine architecture of all layers.
      For details on how architecture is determined,
      see `torch API documentation <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_.

      :type: :obj:`bool`


   .. py:attribute:: padding_mode

      padding mode that determine architecture of all layers.
      For details on how architecture is determined,
      see `torch API documentation <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_.

      :type: :obj:`str`


   .. py:attribute:: act

      activation function applied between all layers.

      :type: :obj:`torch.nn.Module`


   .. py:attribute:: kernel_sizes
      :value: []


      list of kernel_sizes that
      determine architecture of each layer.
      Each kernel_size can be either integer or tuple.
      Kernel size is automatically determined so that
      output of the corresponding layer has the shape of the next layer.

      For details on how architecture is determined,
      see `torch API documentation <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_.

      :type: :obj:`list`


   .. py:attribute:: fcs
      :value: []


      module list of
      :obj:`torch.nn.Conv2d` (forward) or :obj:`torch.nn.Conv2d` (backward).

      :type: :obj:`torch.nn.ModuleList`


   .. py:attribute:: data_shape

      tensor dimension of the training data
      that will be passed into/out of the module.

      :type: :obj:`list(int)`


   .. py:attribute:: batch_reshape
      :value: None


      tensor dimension to which input/output data is reshaped.

      - Forward :attr:`mode`: shape of 3d-/4d-array
      - Backward :attr:`mode`: shape of arbitrary nd-array

      Determined by :meth:`set_data_shape`.

      :type: :obj:`list(int)`


   .. py:method:: set_data_shape(data_shape: list)

      Set the batch reshape in order to reshape the input/output batches
      based on given training data shape.

      Forward :attr:`mode`:

          For :obj:`data_shape` :math:`=[N_1,\ldots,N_m]`
          and the first layer size of :math:`[C_1, H_1, W_1]`,

          .. math::
              batch\_reshape = [R_1, C_1, H_1, W_1],

          where :math:`\prod_{i=1}^m N_i = R_1\times C_1\times H_1\times W_1`.

          If :math:`m=2` and :math:`C_1=1`, then

          .. math::
              batch\_reshape = [C_1, H_1, W_1].

      .. note:: For forward mode, :obj:`data_shape[-2:]==self.layer_sizes[0, 1:]` must be true.

      Backward :attr:`mode`:

          :attr:`batch_shape` is the same as :obj:`data_shape`.
          Output tensor of the module is reshaped as :obj:`data_shape`.

      :Parameters: **data_shape** (:obj:`list(int)`) -- Shape of the input/output data tensor for forward/backward mode.



   .. py:method:: print_data_shape()

      Print out the data shape and architecture of the module.



   .. py:method:: forward(x)

      Evaluate through the module.

      :Parameters: **x** (:obj:`torch.nn.Tensor`) -- Input tensor to pass into the module.

                   - Forward mode: nd array of shape :attr:`data_shape`
                   - Backward mode: Same shape as the output tensor of forward mode

      :returns: Output tensor evaluated from the module.

                - Forward mode: 3d array of shape :obj:`self.layer_sizes[-1]`,
                  or 4d array of shape :obj:`[self.batch_reshape[0]] + self.layer_sizes[-1]`
                - Backward mode: nd array of shape :attr:`data_shape` (equal to :attr:`batch_shape`)
      :rtype: :obj:`torch.nn.Tensor`



   .. py:method:: compute_kernel_size(input_shape, output_shape, stride, padding, dilation, mode)
      :classmethod:


      Compute kernel size that produces desired output shape from given input shape.

      The formula is based on torch API documentation
      for `Conv2d <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_
      and `ConvTranspose2d <https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html>`_.

      :Parameters: * **input_shape** (:obj:`int` or :obj:`tuple(int)`)
                   * **output_shape** (:obj:`int` or :obj:`tuple(int)`)
                   * **stride** (:obj:`int` or :obj:`tuple(int)`)
                   * **padding** (:obj:`int` or :obj:`tuple(int)`)
                   * **dilation** (:obj:`int` or :obj:`tuple(int)`)
                   * **mode** (:class:`CNN2D.Mode`) -- Direction of CNN. Either :attr:`CNN2D.Mode.Forward` or :attr:`CNN2D.Mode.Backward`

      :returns: List of two integers indicating height and width of kernel.
      :rtype: :obj:`list(int)`



   .. py:method:: compute_input_layer_size(output_shape, kernel_size, stride, padding, dilation, mode)
      :classmethod:


      Compute input layer size that produces desired output shape with given kernel size.

      The formula is based on torch API documentation
      for `Conv2d <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_
      and `ConvTranspose2d <https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html>`_.

      :Parameters: * **output_shape** (:obj:`int` or :obj:`tuple(int)`)
                   * **kernel_size** (:obj:`int` or :obj:`tuple(int)`)
                   * **stride** (:obj:`int` or :obj:`tuple(int)`)
                   * **padding** (:obj:`int` or :obj:`tuple(int)`)
                   * **dilation** (:obj:`int` or :obj:`tuple(int)`)
                   * **mode** (:class:`CNN2D.Mode`) -- Direction of CNN. Either :attr:`CNN2D.Mode.Forward` or :attr:`CNN2D.Mode.Backward`

      :returns: List of two integers indicating height and width of input layer.
      :rtype: :obj:`list(int)`



   .. py:method:: compute_output_layer_size(input_shape, kernel_size, stride, padding, dilation, mode)
      :classmethod:


      Compute output layer size produced from given input shape and kernel size.

      The formula is based on torch API documentation
      for `Conv2d <https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>`_
      and `ConvTranspose2d <https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html>`_.

      :Parameters: * **input_shape** (:obj:`int` or :obj:`tuple(int)`)
                   * **kernel_size** (:obj:`int` or :obj:`tuple(int)`)
                   * **stride** (:obj:`int` or :obj:`tuple(int)`)
                   * **padding** (:obj:`int` or :obj:`tuple(int)`)
                   * **dilation** (:obj:`int` or :obj:`tuple(int)`)
                   * **mode** (:class:`CNN2D.Mode`) -- Direction of CNN. Either :attr:`CNN2D.Mode.Forward` or :attr:`CNN2D.Mode.Backward`

      :returns: List of two integers indicating height and width of output layer.
      :rtype: :obj:`list(int)`



   .. py:method:: init_weight()

      Initialize weights of linear features according to Xavier uniform distribution.



.. py:function:: initial_condition_latent(param_grid, physics, autoencoder)

   Outputs the initial condition in the latent space: Z0 = encoder(U0)



.. py:class:: LatentSpace(physics, config)

   Bases: :py:obj:`torch.nn.Module`


   .. py:attribute:: qgrid_size


   .. py:attribute:: n_z


   .. py:method:: forward(x)


   .. py:method:: export()


   .. py:method:: load(dict_)

      .. rubric:: Notes

      This abstract class only checks if the variables in restart file are the same as the instance attributes.



.. py:class:: Autoencoder(physics, config)

   Bases: :py:obj:`LatentSpace`


   .. py:attribute:: space_dim


   .. py:attribute:: encoder


   .. py:attribute:: decoder


   .. py:method:: forward(x)


   .. py:method:: export()


   .. py:method:: load(dict_)

      .. rubric:: Notes

      This abstract class only checks if the variables in restart file are the same as the instance attributes.



.. py:class:: Conv2DAutoencoder(physics, config)

   Bases: :py:obj:`LatentSpace`


   .. py:attribute:: encoder


   .. py:attribute:: decoder


   .. py:method:: forward(x)


   .. py:method:: export()


   .. py:method:: load(dict_)

      .. rubric:: Notes

      This abstract class only checks if the variables in restart file are the same as the instance attributes.



   .. py:method:: set_batch_shape(batch_shape)


   .. py:method:: print_architecture()


